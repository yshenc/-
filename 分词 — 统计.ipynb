{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pyhanlp import *\n",
    "from gensim import corpora, models, similarities\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"创建停用词列表\"\"\"\n",
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open('./哈工大停用词表.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_depart(sentence):\n",
    "    sentence_depart = HanLP.segment(sentence)\n",
    "    stopwords = stopwordslist()\n",
    "    outstr = ''\n",
    "    for word in sentence_depart:\n",
    "        word = word.toString()\n",
    "        judge = word.split('/')\n",
    "        if judge[0] not in stopwords and ('n' in judge[1] or 'v' in judge[1] or 'q' in judge[1]):\n",
    "            outstr += word\n",
    "            outstr += \" \"\n",
    "    # outstr：'黄蜂 湖人 首发 科比 带伤 战 保罗 加索尔 ...'       \n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教育培训.xlsx\n",
      "旅游交通.xlsx\n",
      "汽车行业.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "网络购物.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "电子电器.xlsx\n",
      "婚恋交友.xlsx\n",
      "共享服务.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "网络服务.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "金融保险.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "房产家居.xlsx\n",
      "其它.xlsx\n",
      "删除停用词和分词成功！！！\n",
      "物流快递.xlsx\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('../'): \n",
    "    for d in dirs:\n",
    "        if d == '分词统计':\n",
    "            for file in files:\n",
    "                if '.xlsx' in file:\n",
    "                    print(file)\n",
    "                    outfilename = './' + file.split('.')[0] + '.txt'\n",
    "                    if not os.path.exists(outfilename):\n",
    "                        inputs = pd.read_excel('../'+file)\n",
    "                        outputs = open(outfilename, 'w', encoding='UTF-8')\n",
    "\n",
    "                        # 把非汉字的字符全部去掉\n",
    "                        for line in inputs['cpi_content']:\n",
    "                            line = re.sub(r'[^\\u4e00-\\u9fa5]+','',str(line))\n",
    "                            line_seg = seg_depart(line.strip())\n",
    "                            outputs.write(line_seg.strip() + '\\n')\n",
    "\n",
    "                        outputs.close()\n",
    "                        print(\"删除停用词和分词成功！！！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教育培训.xlsx\n",
      "旅游交通.xlsx\n",
      "汽车行业.xlsx\n",
      "测试.txt\n",
      "网络购物.xlsx\n",
      "电子电器.xlsx\n",
      ".DS_Store\n",
      "婚恋交友.xlsx\n",
      "共享服务.xlsx\n",
      "网络服务.xlsx\n",
      "金融保险.xlsx\n",
      "房产家居.xlsx\n",
      "其它.xlsx\n",
      "物流快递.xlsx\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('../'): \n",
    "    for d in dirs:\n",
    "        if d == '分词统计':\n",
    "            for file in files:\n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('./'): \n",
    "    for file in files:\n",
    "        if '.txt' in file:\n",
    "            fr = open(file, 'r',encoding='utf-8')\n",
    "            v_count = {}\n",
    "            n_count = {}\n",
    "            for line in fr.readlines():\n",
    "                lline = line.split(' ')\n",
    "                for word in lline:\n",
    "                    if 'v' in word:\n",
    "                        v_word = word.split('/')[0]\n",
    "                        try:\n",
    "                            v_count[v_word] = v_count[v_word] + 1\n",
    "                        except:\n",
    "                            v_count[v_word] = 1\n",
    "                    elif 'n' in word:\n",
    "                        n_word = word.split('/')[0]\n",
    "                        try:\n",
    "                            n_count[n_word] = n_count[n_word] + 1\n",
    "                        except:\n",
    "                            n_count[n_word] = 1\n",
    "            if not os.path.exists(file.split('.')[0]+'名词排名.xlsx'):\n",
    "                n_count_pd = pd.DataFrame({'名词':list(n_count.keys()), '数量':list(n_count.values())})\n",
    "                n_count_pd.to_excel(file.split('.')[0]+'名词排名.xlsx', index = False)\n",
    "            if not os.path.exists(file.split('.')[0]+'动词排名.xlsx'):\n",
    "                v_count_pd = pd.DataFrame({'动词':list(v_count.keys()), '数量':list(v_count.values())})\n",
    "                v_count_pd.to_excel(file.split('.')[0]+'动词排名.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>名词</th>\n",
       "      <th>数量</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>月</td>\n",
       "      <td>10352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>客服</td>\n",
       "      <td>7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>合同</td>\n",
       "      <td>7531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>公司</td>\n",
       "      <td>5762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>要求</td>\n",
       "      <td>5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>押金</td>\n",
       "      <td>4881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>电话</td>\n",
       "      <td>4658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>平台</td>\n",
       "      <td>4449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>问题</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>房子</td>\n",
       "      <td>3881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     名词     数量\n",
       "112   月  10352\n",
       "55   客服   7732\n",
       "21   合同   7531\n",
       "113  公司   5762\n",
       "92   要求   5031\n",
       "116  押金   4881\n",
       "6    电话   4658\n",
       "175  平台   4449\n",
       "14   问题   4320\n",
       "11   房子   3881"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_count_pd = pd.DataFrame({'名词':list(n_count.keys()), '数量':list(n_count.values())})\n",
    "n_count_pd.sort_values(by='数量',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>动词</th>\n",
       "      <th>数量</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>说</td>\n",
       "      <td>11846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>没有</td>\n",
       "      <td>10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>联系</td>\n",
       "      <td>5116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>还款</td>\n",
       "      <td>4103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>退款</td>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>投诉</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>处理</td>\n",
       "      <td>3164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>退</td>\n",
       "      <td>2928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>租房</td>\n",
       "      <td>2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>贷</td>\n",
       "      <td>2855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     动词     数量\n",
       "38    说  11846\n",
       "11   没有  10153\n",
       "113  联系   5116\n",
       "588  还款   4103\n",
       "125  退款   3500\n",
       "162  投诉   3279\n",
       "106  处理   3164\n",
       "372   退   2928\n",
       "91   租房   2863\n",
       "742   贷   2855"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_count_pd = pd.DataFrame({'动词':list(v_count.keys()), '数量':list(v_count.values())})\n",
    "v_count_pd.sort_values(by='数量',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenshen/anaconda3/lib/python3.6/site-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import jpype\n",
    "\n",
    "#路径\n",
    "jvmPath = jpype.getDefaultJVMPath() # 获得系统的jvm路径\n",
    "ext_classpath = r\"./ner/hanlp\\hanlp-1.6.3.jar:./ner/hanlp\"\n",
    "jvmArg = '-Djava.class.path=' + ext_classpath\n",
    "jpype.startJVM(jvmPath, jvmArg, \"-Xms1g\", \"-Xmx1g\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place': [' 高新区/ns', ' 武汉/ns', ' 武汉/ns', ' 高新区/ns', ' 武汉/ns', ' 武汉/ns', ' 成都/ns', ' 高新区/ns'], 'person': [' 仁和/nr', ' 仁和/nr'], 'organization': [], 'time': [' 2017年/t', ' 2018年6月30日/t', ' 当时/t', ' 不久/t', ' 后期/t', ' 2019年3月/t', ' 后期/t', ' 2019年/t', ' 6月/t', ' 本月/t']}\n"
     ]
    }
   ],
   "source": [
    "import jpype\n",
    "jvmPath = jpype.getDefaultJVMPath() # 获得系统的jvm路径\n",
    "\n",
    "\n",
    "#繁体转简体\n",
    "def TraditionalChinese2SimplifiedChinese(sentence_str):\n",
    "    HanLP = jpype.JClass('com.hankcs.hanlp.HanLP')\n",
    "    return HanLP.convertToSimplifiedChinese(sentence_str)\n",
    "\n",
    "#切词&命名实体识别与词性标注(可以粗略识别)\n",
    "def NLP_tokenizer(sentence_str):\n",
    "    NLPTokenizer = jpype.JClass('com.hankcs.hanlp.tokenizer.NLPTokenizer')\n",
    "    return NLPTokenizer.segment(sentence_str)\n",
    "\n",
    "#地名识别，标注为ns\n",
    "def Place_Recognize(sentence_str):\n",
    "    HanLP = jpype.JClass('com.hankcs.hanlp.HanLP')\n",
    "    segment = HanLP.newSegment().enablePlaceRecognize(True)\n",
    "    return HanLP.segment(sentence_str)\n",
    "\n",
    "#人名识别,标注为nr\n",
    "def PersonName_Recognize(sentence_str):\n",
    "    HanLP = jpype.JClass('com.hankcs.hanlp.HanLP')\n",
    "    segment = HanLP.newSegment().enableNameRecognize(True)\n",
    "    return HanLP.segment(sentence_str)\n",
    "\n",
    "#机构名识别,标注为nt\n",
    "def Organization_Recognize(sentence_str):\n",
    "    HanLP = jpype.JClass('com.hankcs.hanlp.HanLP')\n",
    "    segment = HanLP.newSegment().enableOrganizationRecognize(True)\n",
    "    return HanLP.segment(sentence_str)\n",
    "\n",
    "#标注结果转化成列表\n",
    "def total_result(function_result_input):\n",
    "    x = str(function_result_input)\n",
    "    y = x[1:len(x)-1]\n",
    "    y = y.split(',')\n",
    "    return y\n",
    "\n",
    "#时间实体\n",
    "def time_result(total_result):\n",
    "    z = []\n",
    "    for i in range(len(total_result)):\n",
    "        if total_result[i][-2:] == '/t':\n",
    "            z.append(total_result[i])\n",
    "    return z\n",
    "\n",
    "#Type_Recognition 可以选 ‘place’,‘person’,‘organization’三种实体,\n",
    "#返回单一实体类别的列表\n",
    "def single_result(Type_Recognition,total_result):\n",
    "    if Type_Recognition == 'place':\n",
    "        Type = '/ns'\n",
    "    elif Type_Recognition == 'person':\n",
    "        Type = '/nr'\n",
    "    elif Type_Recognition == 'organization':\n",
    "        Type = '/nt'\n",
    "    else:\n",
    "        print ('请输入正确的参数：（place，person或organization）')\n",
    "    z = []\n",
    "    for i in range(len(total_result)):\n",
    "        if total_result[i][-3:] == Type:\n",
    "            z.append(total_result[i])\n",
    "    return z\n",
    "\n",
    "#把单一实体结果汇总成一个字典\n",
    "def dict_result(sentence_str):\n",
    "    sentence = TraditionalChinese2SimplifiedChinese(sentence_str)\n",
    "    total_dict = {}\n",
    "    a = total_result(Place_Recognize(sentence))\n",
    "    b = single_result('place',a)\n",
    "    c = total_result(PersonName_Recognize(sentence))\n",
    "    d = single_result('person',c)\n",
    "    e = total_result(Organization_Recognize(sentence))\n",
    "    f = single_result('organization',e)\n",
    "    g = total_result(NLP_tokenizer(sentence))\n",
    "    h = time_result(g)\n",
    "    total_list = [i for i in [b,d,f,h]]\n",
    "    total_dict.update(place = total_list[0],person = total_list[1],organization = total_list[2],time = total_list[3])\n",
    "    jpype.shutdownJVM()#关闭JVM虚拟机\n",
    "    return total_dict\n",
    "\n",
    "#测试\n",
    "test_sentence='本人在2017年通过家人缴费9800元到仁和会计学校高新校区学习会计核算班后，在2018年6月30日，该校销售人员又诱导我缴费30000元报名主管会计班、CMA课程，由于我当时毕业不久刚出来工作，没有更多的资金缴费，于是该机构工作人员又诱导并操纵我的手机在智联好期贷APP上贷款交费，让我后期无故承担利息，并导致我征信出现逾期，迫于无奈我只好还完所有款项。 在缴纳该笔3万元用后，该机构没有给我签署任何书面合同，也没有开具任何票据，更也没有给我安排具体的课程，一直到2019年3月打电话询问校区老师，校区老师说还没有开课，后期会通知我，一直到2019年6月还是未收到任何通知及电话，本人根本不知道他们课程如何安排，并且该机构人员流动巨大，报名时的工作人员后续均离职。由于本人有孕在身，身体不佳，没有很多心思来处理，但是时至今日我才发现事情的严重性，我感受到我受到了欺骗。我多次到该机构现场沟通退费事宜，但该机构采用踢皮球方式处理，高新区分校让我找武汉总部，我致电武汉总部又让我找高新分校（我一直联系的是高新区仁和会计培训机构，不知道为何要让我找武汉总部？）。在维权过程中，我发现该机构如下违法事实： 1、与报名人不签订书面合同。在报名后，我惊讶的发现该机构的app上多了一个协议，协议金额只有3200元。我根本不知道这个协议的存在，也没有签过字，根本不是我的意思表示，但协议末尾签署名字居然是机器打印上我的名字。 2、该机构无资质。依据国家法律规定，开设培训机构需要有营业执照和办学资质并且悬挂在营业场所，但是该校区未悬挂相关资质文件。我多次要求提供，其敷衍告知我去找武汉总部要（我报名和联系的一直是成都高新区仁和会计培训机构，为何要求我找总部？）。足以表明该机构是挂靠在仁和会计总部名下，期满社会人士报名学习，却没有办学资质。 3、偷税漏税。该机构诱导我通过智联好期贷APP贷款缴费后，并未开具相关发票和收据。我询问其负责人，其告知“学员没有要求，我们就不会开票”，更是以本月发票不够还在领票中，开票要总部开等各种理由来推迟开发票，直到现在校区还是没有给我开任何发票，足以表明其偷税漏税行为。 4、恶意串通第三方贷款公司。故意诱导学院和第三方平台贷款缴纳学费，未提前告知利息情况。 请：1、仁和会计高新校区退还本人学费。2、请求行政机关依法查处其违法行为。'\n",
    "print (dict_result(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
